/*
 * This is a test for stat run time optimizations.  Each stat has a list of
 * requested statistical operators.  For instance, if a script uses stat x,
 * and only refers to @avg(x), then the list of requested statistical operators
 * for given stat x is @count, @sum, and @avg. The  @min(x) and @max(x) are
 * not in the list, and thus do not need to be avaluated at the _stp_stat_add()
 * time (iow, at the x<<<val time).  Optimization based on this makes the
 * systemtap runtime run faster. The goal of this test is to verify that this
 * sort of optimizations actually works in a measurable way.
 *
 * At the moment, the available stat operators are @count, @sum, @min, @max,
 * @avg, and @variance.  The most computionally expensive is @variance.
 * Detecting the variance optimization is quite simple.  Other operators are
 * computionally cheap and thus detecting their respective optimizations is
 * somewhat tricky on a multiuser/multitasking system, where so many irrelevant
 * bearings are affecting our fragile measurement.  In this case we must set
 * the treshold distinguishing between the PASS and FAIL pretty carefully.  Just
 * slightly above the "noise".  This testcase is sentenced to be fragile by it's
 * nature though.
 *
 * One of the basic assumptions for this sort of test is that if we compare stats
 * having identical list of requested statistical operators, we should get very
 * similar results.  It turns out, that to achieve this, we can't simply feed the
 * values into measured stats in straightforward order. Instead, we need to baffle
 * the optimizations under the hood by complicating the "feed" order slightly.
 * After verifying this assumption, we can start comparing different stats.
 *
 * Since verifying the @variance optimization is much easirer and doesn't require
 * so many time consuming iterations to get reasonable results, this test is
 * divided into two parts, TEST 1, and TEST 2, where in TEST 1 we focus on the
 * optimization for @count, @sum, @min, and @max, and then, in TEST 2, we test the
 * @variance optimization separately. This makes the test itself run faster.
 *
 */

@define RANDCNT %( 200000 %)
@define RANDMAX %( 1000 %)
@define ITERS %( 1500 %)

@define feed(agg, tagg)
%(
    t = time()
    foreach(k in randvals)
	@agg <<< k
    @tagg += time() - t
%)

global x, tx = 0, y, ty = 0
global a, ta = 0, b, tb = 0
global randvals[@RANDCNT]

function time() { return gettimeofday_us() }

probe begin
{
    /* TEST 1: test optimizations for @count, @sum, @min, and @max. */

    for (i=0; i<@ITERS; i++)
    {

	for (j=0; j<@RANDCNT; j++)
	    randvals[j] = randint(@RANDMAX)

	/* The "ordering dance" described above happens here */
	if(i%2)
	{
	    @feed(x, tx)
	    @feed(y, ty)
	}
	else
	{
	    @feed(y, ty)
	    @feed(x, tx)
	}
    }

    /*
     * We need to print the stats out to avoid compiler elision.
     * The list of stats mentioned below makes the actual difference
     * between stats under test and is the gist of this test.  The test
     * should show no measurable shrinkage, if the below list doesn't
     * differ for measured stats.
     */
    printdln(" ", "IGNORE", @count(x))
    printdln(" ", "IGNORE", @count(y), @sum(y), @min(y), @max(y))

    /* Measured shrinkage [%] */
    shrinkage = (ty-tx)*100/ty

    /*
     * Treshold [%] (just slightly above the "noise") The usual values were
     * around 8% at the time of writing this test using gcc-6.2.1-1.fc26.x86_64.
     * But deeper testing shows, that on other arches, namely on power and arm,
     * gcc is not so good optimizing the runtime code, so here we only check
     * for regressions.
     */
    treshold = 0

    printf("%s test1 (%d)\n", ((shrinkage >= treshold) ? "PASS" : "FAIL"), shrinkage)


    /* TEST 2: test optimizations for @variance. */

    for (i=0; i<(@ITERS / 4); i++)
    {

	for (j=0; j<@RANDCNT; j++)
	    randvals[j] = randint(@RANDMAX)

	if(i%2)
	{
	    @feed(a, ta)
	    @feed(b, tb)
	}
	else
	{
	    @feed(b, tb)
	    @feed(a, ta)
	}
    }

    printdln(" ", "IGNORE", @count(a))
    printdln(" ", "IGNORE", @variance(b))

    shrinkage = (tb-ta)*100/tb

    /*
     * Treshold [%], for this test the usual value is around 68% at the time
     * of writing this test.
     */
    treshold = 20

    printf("%s test2 (%d)\n", ((shrinkage >= treshold) ? "PASS" : "FAIL"), shrinkage)

    exit()
}
